var documenterSearchIndex = {"docs":
[{"location":"manual/model/","page":"Model","title":"Model","text":"CurrentModule = BlockOpt\nDocTestSetup = quote\nimport BlockOpt: Model, name, obj, grad!, grad, objective, gradient, initial_iterate, formula,\n    dimension, directory, objective!, gradient!, initial_iterate!, formula!,\n    hess_sample, hessAD\nend","category":"page"},{"location":"manual/model/#Model","page":"Model","title":"Model","text":"","category":"section"},{"location":"manual/model/","page":"Model","title":"Model","text":"Model","category":"page"},{"location":"manual/model/#BlockOpt.Model","page":"Model","title":"BlockOpt.Model","text":"Model\n\nSpecifies the unconstrianed minimization of a smooth objective function. A model is minimally constructed with a name and may be incrementally loaded. Once a model is loaded, the objective, and gradient function may no longer be modified. A model creates a directory storing logged information throughout a model instances life. The directory can be found relative to your current working directory with the name associated with the model.\n\n\n\n\n\n","category":"type"},{"location":"manual/model/#Interface","page":"Model","title":"Interface","text":"","category":"section"},{"location":"manual/model/","page":"Model","title":"Model","text":"name\nobjective\ngradient\ninitial_iterate\nformula\ndimension\ndirectory\nobjective!\ngradient!\ninitial_iterate!\nformula!\nobj\ngrad!\nhessAD\nhess_sample","category":"page"},{"location":"manual/model/#BlockOpt.name","page":"Model","title":"BlockOpt.name","text":"name(m::Model)\n\nThe name associated with model m as given to m's constructor.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.objective","page":"Model","title":"BlockOpt.objective","text":"objective(m::Model)\n\nThe objective function of model m, having an unassigned default value of missing.\n\nSee objective! to load a model's objective.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.gradient","page":"Model","title":"BlockOpt.gradient","text":"gradient(m::Model)\n\nThe gradient function of model m, having an unassigned default value of missing.\n\nSee gradient! to load a m's gradient.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.initial_iterate","page":"Model","title":"BlockOpt.initial_iterate","text":"initial_iterate(m::Model)\n\nThe initial iterate of model m, having an unassigned default value of missing.\n\nSee initial_iterate! to load m's starting location.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.formula","page":"Model","title":"BlockOpt.formula","text":"formula(m::Model)\n\nThe formula of model m, having an unassigned default value of missing.\n\nSee formula! to set m's formula.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.dimension","page":"Model","title":"BlockOpt.dimension","text":"dimension(m::Model)\n\nThe dimension of model m, which is missing so long as the initial iterate isn't specified.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.directory","page":"Model","title":"BlockOpt.directory","text":"directory(m::Model)\n\nThe directory path of model m, with the relative portion given by the name of m.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.objective!","page":"Model","title":"BlockOpt.objective!","text":"objective!(m::Model, f)\n\nAssign model m the objective function f.\n\nIf the model is final, the call simply returns without modifying the model.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.gradient!","page":"Model","title":"BlockOpt.gradient!","text":"gradient!(m::Model, ∇f!)\n\nAssign model m the in-place gradient function ∇f!, of the form\n\n∇f!(out, x) = (out .= ∇f(x))\n\nwhere ∇f(x) is the steepest descent direction at x in stored the place of the inputed buffer out.\n\nIf the model is final, the call simply returns without modifying the model.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.initial_iterate!","page":"Model","title":"BlockOpt.initial_iterate!","text":"initial_iterate!(m::Model, x0)\n\nAssign model m an initial starting location, ideally a resonable guess of a minima for the models objective function.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.formula!","page":"Model","title":"BlockOpt.formula!","text":"formula!(m::Model, f)\n\nAssign model m an escaped LaTeX string. The formula is used in logging visuals related to model m.\n\nExample\n\njulia> dot_formila = \"$ f(x) = x⋅x $\"; \njulia> formula!(m, dot_formila);\n\nHere, the euclidean squared distance formula now represent's m's objective formula.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.obj","page":"Model","title":"BlockOpt.obj","text":"obj(m::Model, x)\n\nEvaluates the objective function of model m at x.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.grad!","page":"Model","title":"BlockOpt.grad!","text":"grad!(m::Model, out, x)\n\nEvaluates the in-place gradient function of model m at x, storing the steepest descent direction in the place of input buffer out.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.hessAD","page":"Model","title":"BlockOpt.hessAD","text":"hessAD(m::Model, x)\n\nThe dense Hessian matrix of model m's objective function at the point x. The computation uses ForwardDiff.jacobian forward-mode AD function on the model's  gradient function.\n\n\n\n\n\n","category":"function"},{"location":"manual/model/#BlockOpt.hess_sample","page":"Model","title":"BlockOpt.hess_sample","text":"hess_sample(m::Model, x, dx)\n\nThe hessian vector-product of model m's objective function at the point x  with the vector dx. The gHS routine uses a more effiecient scheme to compute the hessian samples by means of ForwardDiff's Dual numbers.\n\n\n\n\n\n","category":"function"},{"location":"overview/design/","page":"Overview","title":"Overview","text":"CurrentModule = BlockOpt\nDocTestSetup = quote\n    import BlockOpt: Model, Driver, DriverOptions, Simulation, BlockOptTrace, BlockOptBackend, optimize\nend","category":"page"},{"location":"overview/design/#Design","page":"Overview","title":"Design","text":"","category":"section"},{"location":"overview/design/","page":"Overview","title":"Overview","text":"The BlockOpt interface is constructed through a delegation design pattern, leveraging the behavior of existing types by wrapping them in new types. The figure below is a visual representation of the BlockOpt type delegation, where the arrow represents a has-a relationship. ","category":"page"},{"location":"overview/design/","page":"Overview","title":"Overview","text":"(Image: )","category":"page"},{"location":"overview/design/","page":"Overview","title":"Overview","text":"Here, the blue shaded types are exposed to the user. The red boxes   hold Algorithm 7.1's routine and all observations collected throughout the iteration.","category":"page"},{"location":"overview/design/","page":"Overview","title":"Overview","text":"The immutable Driver has-a mutable DriverOptions, which effictively delegates the  simulation options to the Driver via forwarded/inherted functionality. A user-loaded Model and Driver instances are passed to the Simulation type. Then the Simulation controls the entry-point and exit-point of the iteration. Last, a Trace records Backend information throughout the iteration and a Simulation controls the observations information flow.","category":"page"},{"location":"overview/design/#optimize","page":"Overview","title":"optimize","text":"","category":"section"},{"location":"overview/design/","page":"Overview","title":"Overview","text":"optimize","category":"page"},{"location":"overview/design/#BlockOpt.optimize","page":"Overview","title":"BlockOpt.optimize","text":"optimize(model::Model, driver::Driver)\n\nAn entry-point into the minimization iteration with the given model subject to the specified driver.\n\n\n\n\n\noptimize(model::Model, driver::Driver)\n\nAttempts to determine the unconstrained minimum of f via a first-order method with the initial iterate given by x₀. The gradient ∇f! must be specified as an inplace operation.\n\n\n\n\n\n","category":"function"},{"location":"overview/design/#Entry-Point:-optimize-call.","page":"Overview","title":"Entry Point: optimize call.","text":"","category":"section"},{"location":"overview/design/","page":"Overview","title":"Overview","text":"The entry-point occurs when a user makes a function call to optimize.","category":"page"},{"location":"overview/design/#Exit-Point:-optimize-return.","page":"Overview","title":"Exit Point: optimize return.","text":"","category":"section"},{"location":"overview/design/","page":"Overview","title":"Overview","text":"Upon an optimize call a Simulation instance s is created and passed to the fallback method optimize!(s). The exit-point occurs when optimize! returns  simulation s at a terminal state. ","category":"page"},{"location":"manual/options/","page":"Options","title":"Options","text":"CurrentModule = BlockOpt\nDocTestSetup = quote\nimport BlockOpt: DriverOptions, samples, Δ_max, δ_tol, ϵ_tol, max_iterations, weave_level, log_level,\n    samples!, Δ_max!, δ_tol!, ϵ_tol!, max_iterations!, weave_level!, log_level!\nend","category":"page"},{"location":"manual/options/#Options","page":"Options","title":"Options","text":"","category":"section"},{"location":"manual/options/","page":"Options","title":"Options","text":"DriverOptions","category":"page"},{"location":"manual/options/#BlockOpt.DriverOptions","page":"Options","title":"BlockOpt.DriverOptions","text":"DriverOptions\n\nSpecifies Driving parameters used in a Simulation instance.\n\n\n\n\n\n","category":"type"},{"location":"manual/options/#Interface","page":"Options","title":"Interface","text":"","category":"section"},{"location":"manual/options/","page":"Options","title":"Options","text":"The DriverOptrions type is best thought of as the mutable protion of a Driver instance. The methods below are simple fallbacks of the forwarded Driver methods.","category":"page"},{"location":"manual/options/","page":"Options","title":"Options","text":"note: Note\nIt is possible to pass a DriverOptions instance as the options keyword argument to a Driver constructor.","category":"page"},{"location":"manual/options/","page":"Options","title":"Options","text":"samples(o::DriverOptions)\nΔ_max(o::DriverOptions)\nδ_tol(o::DriverOptions)\nϵ_tol(o::DriverOptions)\nmax_iterations(o::DriverOptions)\nweave_level(o::DriverOptions)\nlog_level(o::DriverOptions)\nsamples!\nΔ_max!\nδ_tol!\nϵ_tol!\nmax_iterations!\nweave_level!\nlog_level!","category":"page"},{"location":"manual/options/#BlockOpt.samples-Tuple{BlockOpt.DriverOptions}","page":"Options","title":"BlockOpt.samples","text":"samples(o::DriverOptions)\n\nThe number of hessian samples taken at each succussful step in a simulation. \n\n\n\n\n\n","category":"method"},{"location":"manual/options/#BlockOpt.Δ_max-Tuple{BlockOpt.DriverOptions}","page":"Options","title":"BlockOpt.Δ_max","text":"Δ_max(o::DriverOptions)\n\nThe maximum trust-region radius of a driven simulation.\n\n\n\n\n\n","category":"method"},{"location":"manual/options/#BlockOpt.δ_tol-Tuple{BlockOpt.DriverOptions}","page":"Options","title":"BlockOpt.δ_tol","text":"δ_tol(o::DriverOptions)\n\nThe relative tolerance passed to pinv while performing a block QN update.\n\n\n\n\n\n","category":"method"},{"location":"manual/options/#BlockOpt.ϵ_tol-Tuple{BlockOpt.DriverOptions}","page":"Options","title":"BlockOpt.ϵ_tol","text":"ϵ_tol(o::DriverOptions)\n\nThe absolute convergence tolerance, occuring at xₖ such that f(xₖ)  ϵ.\n\n\n\n\n\n","category":"method"},{"location":"manual/options/#BlockOpt.max_iterations-Tuple{BlockOpt.DriverOptions}","page":"Options","title":"BlockOpt.max_iterations","text":"max_iterations(o::DriverOptions)\n\nThe maximum number of iterations for a driven simulation.\n\n\n\n\n\n","category":"method"},{"location":"manual/options/#BlockOpt.weave_level-Tuple{BlockOpt.DriverOptions}","page":"Options","title":"BlockOpt.weave_level","text":"weave_level(o::DriverOptions)\n\nReturns the current weave level of a simulation.\n\n\n\n\n\n","category":"method"},{"location":"manual/options/#BlockOpt.log_level-Tuple{BlockOpt.DriverOptions}","page":"Options","title":"BlockOpt.log_level","text":"log_level(o::DriverOptions)\n\nReturns the current logging level of a simulation\n\n\n\n\n\n","category":"method"},{"location":"manual/options/#BlockOpt.samples!","page":"Options","title":"BlockOpt.samples!","text":"samples!(o::DriverOptions, s)\n\nSet the number of hessian samples collected during each succussful step to some even natrual s where s = 2w.\n\n\n\n\n\n","category":"function"},{"location":"manual/options/#BlockOpt.Δ_max!","page":"Options","title":"BlockOpt.Δ_max!","text":"δ_tol!(o::DriverOptions, δ)\n\nSet the maximum trust-region radius to some positive Δ.\n\n\n\n\n\n","category":"function"},{"location":"manual/options/#BlockOpt.δ_tol!","page":"Options","title":"BlockOpt.δ_tol!","text":"δ_tol!(o::DriverOptions, δ)\n\nSet the pinv relative tolerance used in the QN update to some positive δ.\n\n\n\n\n\n","category":"function"},{"location":"manual/options/#BlockOpt.ϵ_tol!","page":"Options","title":"BlockOpt.ϵ_tol!","text":"ϵ_tol!(o::DriverOptions, ϵ)\n\nSet the terminal convergence tolerance to some positive ϵ.\n\n\n\n\n\n","category":"function"},{"location":"manual/options/#BlockOpt.max_iterations!","page":"Options","title":"BlockOpt.max_iterations!","text":"max_iterations!(o::DriverOptions, K)\n\nSet the terminal iteration to the positive integer K.\n\n\n\n\n\n","category":"function"},{"location":"manual/options/#BlockOpt.weave_level!","page":"Options","title":"BlockOpt.weave_level!","text":"weave_level!(o::DriverOptions, level::WeaveLevel)\n\nSet the weave level to NONE or ALL, toggiling the optional Weave.jl generated report of a simulation.\n\n\n\n\n\n","category":"function"},{"location":"manual/options/#BlockOpt.log_level!","page":"Options","title":"BlockOpt.log_level!","text":"log_level!(o::DriverOptions, level::LogLevel)\n\nAssign the simulation logging level to INFO, DEBUG, WARN, or ERROR.\n\n\n\n\n\n","category":"function"},{"location":"manual/simulation/","page":"Simulation","title":"Simulation","text":"CurrentModule = BlockOpt\nDocTestSetup = quote\nimport BlockOpt: Simulation, trs_timer, trs_counter, ghs_timer, ghs_counter, f_vals, ∇f_norms, p_norms,\n    Δ_vals, ρ_vals, objtrace, gradtrace, radiustrace, steptrace, rhotrace","category":"page"},{"location":"manual/simulation/#Simulation","page":"Simulation","title":"Simulation","text":"","category":"section"},{"location":"manual/simulation/","page":"Simulation","title":"Simulation","text":"Simulation","category":"page"},{"location":"manual/simulation/#BlockOpt.Simulation","page":"Simulation","title":"BlockOpt.Simulation","text":"Simulation\n\nEnty point and exit point of an iteration. A simulation composes a iterations trace and backend iteration of Algorithm 7.1.  An instance of a simulation is returned from an optimize call. \n\n\n\n\n\n","category":"type"},{"location":"manual/simulation/#Subroutines-of-optimize!","page":"Simulation","title":"Subroutines of optimize!","text":"","category":"section"},{"location":"manual/simulation/","page":"Simulation","title":"Simulation","text":"When calling optimize(model, driver) the fallback is optimize!(s) where simulation s is internally constructed. The responsibility of s is to orchestrate the iteration defined in it's backend and make observations to generate the trace.","category":"page"},{"location":"manual/simulation/","page":"Simulation","title":"Simulation","text":"The backend defines subroutines for s's memory manipulations for each step in it's iteration. Since then backend delegates it's behavior to s, we dispatch the backends subroutines to s while adding additional execution steps to generate the simulations trace.","category":"page"},{"location":"manual/simulation/","page":"Simulation","title":"Simulation","text":"initialize(s::Simulation)\nterminal(s::Simulation)\nbuild_trs(s::Simulation)\nsolve_trs(s::Simulation)\nbuild_trial(s::Simulation)\naccept_trial(s::Simulation)\nsecantQN(s::Simulation)\nupdate_Sₖ(s::Simulation)\ngHS(s::Simulation)\nblockQN(s::Simulation)","category":"page"},{"location":"manual/simulation/#BlockOpt.initialize-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.initialize","text":"initialize(s::Simulation)\n\nPerforms each step up to the preliminary update to obtain H₀. Lines 1-6 of Algorithm 7.1.\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.terminal-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.terminal","text":"terminal(s::Simulation)\n\nTrue if the state of s is terminal.\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.build_trs-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.build_trs","text":"build_trs(s::Simulation)\n\nBuild arguments for the trs_small call to TRS.jl.\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.solve_trs-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.solve_trs","text":"solve_trs(s::Simulation)\n\nSolve aₖ in Equation (5.5).\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.build_trial-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.build_trial","text":"build_trial(s::Simulation)\n\nBuild trial iterate, evaluate the objective at trial location, and compute ρ.\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.accept_trial-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.accept_trial","text":"accept_trial(s::Simulation)\n\nObserves the value of ρ, accepts positive values and updates xₖ & fₖ.\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.secantQN-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.secantQN","text":"secantQN(s::Simulation)\n\nPerforms the standard secant update for s's inverse hessian approximation Hₖ.\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.update_Sₖ-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.update_Sₖ","text":"update_Sₖ(s::Simulation)\n\nUpdates the 2w-1 sample directions of simulation s.\n\nSee: S_update_a, S_update_b, S_update_c, S_update_d, S_update_e, S_update_f.\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.gHS-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.gHS","text":"gHS(s::Simulation)\n\nSee Algorithm 31\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.blockQN-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.blockQN","text":"blockQN(s::Simulation)\n\nPerforms a block update with multiple descent directions for s's inverse hessian approximation Hₖ.\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#Interface","page":"Simulation","title":"Interface","text":"","category":"section"},{"location":"manual/simulation/","page":"Simulation","title":"Simulation","text":"Methods dispatch on a terminal simulation returned from an optimize call.","category":"page"},{"location":"manual/simulation/","page":"Simulation","title":"Simulation","text":"trs_timer(s::Simulation)\ntrs_counter(s::Simulation)\nghs_timer(s::Simulation)\nghs_counter(s::Simulation)\nf_vals(s::Simulation)\n∇f_norms(s::Simulation)\np_norms(s::Simulation)\nΔ_vals(s::Simulation)\nρ_vals(s::Simulation)","category":"page"},{"location":"manual/simulation/#BlockOpt.trs_timer-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.trs_timer","text":"trs_timer(s::Simulation)\n\nThe elapsed time simulation s has spent in trs_solve(s).\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.trs_counter-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.trs_counter","text":"trs_counter(s::Simulation)\n\nThe count of trust region subproblem subsolves of simulation s.\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.ghs_timer-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.ghs_timer","text":"ghs_timer(s::Simulation)\n\nThe elapsed time simulation s has spent in gHS(s).\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.ghs_counter-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.ghs_counter","text":"ghs_counter(s::Simulation)\n\nThe number of gHS evaluations of simulation s.\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.f_vals-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.f_vals","text":"f_vals(s::Simulation)\n\nA vector storing objective values f(xₖ) for each iterate xₖ.\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.∇f_norms-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.∇f_norms","text":"∇f_norms(s::Simulation)\n\nA vector storing normed gradient values f(xₖ)₂ for each iterate xₖ.\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.p_norms-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.p_norms","text":"p_norms(s::Simulation)\n\nA vector storing the distance of each successful step pₖ₂. \n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.Δ_vals-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.Δ_vals","text":"Δ_vals(s::Simulation)\n\nA vector storing the trust-region radius passed to trs_small of TRS.jl, during each succussful trust-region subproblem solve. \n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#BlockOpt.ρ_vals-Tuple{BlockOpt.Simulation}","page":"Simulation","title":"BlockOpt.ρ_vals","text":"ρ_vals(s::Simulation)\n\nA vector storing the ratio of actual reduction to model reduction of each successful step.\n\n\n\n\n\n","category":"method"},{"location":"manual/simulation/#Recipes","page":"Simulation","title":"Recipes","text":"","category":"section"},{"location":"manual/simulation/","page":"Simulation","title":"Simulation","text":"To use the listed recipes you must have (Plots.jl)[http://docs.juliaplots.org/latest/] in your current namespace, i.e. loaded from calling using Plots. This assumes the Plots package has already been installed through Pkg.jl.","category":"page"},{"location":"manual/simulation/","page":"Simulation","title":"Simulation","text":"objtrace\ngradtrace\nradiustrace\nsteptrace\nrhotrace","category":"page"},{"location":"manual/simulation/#BlockOpt.objtrace","page":"Simulation","title":"BlockOpt.objtrace","text":"objtrace\n\nProvide any number of terminal simulations as arguments and objtrace displays a plot of each arguments objective function values at each succussful iterate.\n\nTo add a simulation to the current objtrace plot use objtrace!.\n\n\n\n\n\n","category":"function"},{"location":"manual/simulation/#BlockOpt.gradtrace","page":"Simulation","title":"BlockOpt.gradtrace","text":"gradtrace\n\nProvide any number of terminal simulations as arguments and gradtrace displays a plot of each arguments normed gradient values at each succussful iterate.\n\nTo add a simulation to the current gradtrace plot use gradtrace!.\n\n\n\n\n\n","category":"function"},{"location":"manual/simulation/#BlockOpt.radiustrace","page":"Simulation","title":"BlockOpt.radiustrace","text":"radiustrace\n\nProvide any number of terminal simulations as arguments and radiustrace displays a plot of each arguments trust region subproblem radius values at each succussful iteration.\n\nTo add a simulation to the current radiustrace plot use radiustrace!.\n\n\n\n\n\n","category":"function"},{"location":"manual/simulation/#BlockOpt.steptrace","page":"Simulation","title":"BlockOpt.steptrace","text":"steptrace\n\nProvide any number of terminal simulations as arguments and steptrace displays a plot of each arguments step measure at each succussful iteration.\n\nTo add a simulation to the current steptrace plot use steptrace!.\n\n\n\n\n\n","category":"function"},{"location":"manual/simulation/#BlockOpt.rhotrace","page":"Simulation","title":"BlockOpt.rhotrace","text":"rhotrace\n\nProvide any number of terminal simulations as arguments and rhotrace displays a plot of each arguments ρ ratio at each successful iteration.\n\nTo add a simulation to the current rhotrace plot use rhotrace!.\n\n\n\n\n\n","category":"function"},{"location":"manual/driver/","page":"Driver","title":"Driver","text":"CurrentModule = BlockOpt\nDocTestSetup = quote\n    import BlockOpt: Driver, pflag, QN_update, SR1, PSB, S_update, S_update_a,\n        S_update_b, S_update_c, S_update_d, S_update_e, S_update_f\nend","category":"page"},{"location":"manual/driver/#Driver","page":"Driver","title":"Driver","text":"","category":"section"},{"location":"manual/driver/","page":"Driver","title":"Driver","text":"Driver","category":"page"},{"location":"manual/driver/#BlockOpt.Driver","page":"Driver","title":"BlockOpt.Driver","text":"Driver\n\nSpecifies the driving parameters of a Simulation instance. A driver is assigned an immutable S_update, QN_update, and pflag upon construction, either by keyword arguments or fallback to the default values.\n\nSee S_update, QN_update, and pflag for more on keyword argument options.\n\n\n\n\n\n","category":"type"},{"location":"manual/driver/#Interface","page":"Driver","title":"Interface","text":"","category":"section"},{"location":"manual/driver/","page":"Driver","title":"Driver","text":"A Driver instance contains a reference to a mutable DriverOptions instance.  Consequently, the delegation design pattern at play allows us to forward the DriverOptions interface to the Driver. In addition to the listed methods, see Options interface section.","category":"page"},{"location":"manual/driver/","page":"Driver","title":"Driver","text":"QN_update(d::Driver)\nSR1\nPSB\nS_update(d::Driver)\nS_update_a\nS_update_b\nS_update_c\nS_update_d\nS_update_e\nS_update_f\npflag(d::Driver)","category":"page"},{"location":"manual/driver/#BlockOpt.QN_update-Tuple{Driver}","page":"Driver","title":"BlockOpt.QN_update","text":"QN_update(d::Driver)\n\nThe QN update formula of Driver d.\n\nOptions: SR1, PSB\n\n\n\n\n\n","category":"method"},{"location":"manual/driver/#BlockOpt.SR1","page":"Driver","title":"BlockOpt.SR1","text":"SR1\n\nReturns the algebraically mininimal SR1 inverse Quasi-Newton block update satisfying the inverse multi-secant condition H  V = U, where δ is the Moore-Penrose psuedoinverse relative tolerance. \n\nSee: Algorithm 42\n\n\n\n\n\n","category":"function"},{"location":"manual/driver/#BlockOpt.PSB","page":"Driver","title":"BlockOpt.PSB","text":"PSB\n\nPowell-Symmetric-Broyden generalized Quasi-Newton block update, where δ is the Moore-Penrose psuedoinverse relative tolerance. \n\nSee: Algorithm 43\n\n\n\n\n\n","category":"function"},{"location":"manual/driver/#BlockOpt.S_update-Tuple{Driver}","page":"Driver","title":"BlockOpt.S_update","text":"S_update(d::Driver)\n\nThe supplemental sample direction update formula of Driver d.\n\nOptions: S_update, S_update_a, S_update_b, S_update_c, S_update_d, S_update_e, S_update_f\n\n\n\n\n\n","category":"method"},{"location":"manual/driver/#BlockOpt.S_update_a","page":"Driver","title":"BlockOpt.S_update_a","text":"S_update_a\n\nRandom set of orthonormal sample directions. \n\nSee: Equation (6.1.a).\n\n\n\n\n\n","category":"function"},{"location":"manual/driver/#BlockOpt.S_update_b","page":"Driver","title":"BlockOpt.S_update_b","text":"S_update_b\n\nRandom set of sample directions orthogonal to the pervious sample space given by input Sₖ.\n\nSee: Equation (6.1.b).\n\n\n\n\n\n","category":"function"},{"location":"manual/driver/#BlockOpt.S_update_c","page":"Driver","title":"BlockOpt.S_update_c","text":"S_update_c\n\nAttempts to guide algorithm to accurately resolve eigen-space associated with the larger Hessian eigenvalues.\n\nSee: Equation (6.1.c).\n\n\n\n\n\n","category":"function"},{"location":"manual/driver/#BlockOpt.S_update_d","page":"Driver","title":"BlockOpt.S_update_d","text":"S_update_d\n\nVariant of (6.1.a) that includes approximate curvature information along the previously choosen step. \n\nSee: Equation (6.1.d).\n\n\n\n\n\n","category":"function"},{"location":"manual/driver/#BlockOpt.S_update_e","page":"Driver","title":"BlockOpt.S_update_e","text":"S_update_e\n\nVariant of (6.1b) that includes approximate curvature information along the previously choosen step. \n\nSee: Equation (6.1.e).\n\n\n\n\n\n","category":"function"},{"location":"manual/driver/#BlockOpt.S_update_f","page":"Driver","title":"BlockOpt.S_update_f","text":"S_update_f\n\nVariant of (6.1c) that includes approximate curvature information along the previously choosen step. \n\nSee: Equation (6.1.f).\n\n\n\n\n\n","category":"function"},{"location":"manual/driver/#BlockOpt.pflag-Tuple{Driver}","page":"Driver","title":"BlockOpt.pflag","text":"pflag(d::Driver)\n\nThe preliminary secant QN update flag of driver d wraping a boolean.\n\nOptions true, false\n\n\n\n\n\n","category":"method"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"CurrentModule = BlockOpt\nDocTestSetup = quote\n    using BlockOpt\n    using LinearAlgebra\nend","category":"page"},{"location":"tutorials/simple/#Simple-Use-Case","page":"Simple Use Case","title":"Simple Use Case","text":"","category":"section"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"Consider the generalized rosenbrock as an objective function which is","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"f(x) = sum_i=1^N-1 left100(x_i+1^2 - x_i^2)^2 + (1 - x_i)^2right","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"We can translate the objective function into julia code as shown below.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> function rosen(x)\n           N = lastindex(x)\n           100sum((x[i + 1] - x[i]^2)^2 for i = 1:N-1) + sum((x[i] - 1)^2 for i = 1:N-1)\n       end","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"Differentiating the objective function and translating to julia code.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> function ∇rosen!(g, x)\n           N = lastindex(x)\n           g[1] = -2 * (1 - x[1]) - 400x[1] * (-x[1]^2 + x[2])\n\n           for i in 2:N-1\n               g[i] = -2 * (1 - x[i]) + 200 * (-x[i - 1]^2 + x[i]) - 400x[i] * (-x[i]^2 + x[1 + i])\n           end\n           \n           g[N] = 200 * (x[N] - x[N-1]^2)    \n           return g\n       end\n∇rosen! (generic function with 1 method)","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"The optimize routine will attempt to find x meeting the first-order neccessary condition  for being a local minimum of f, i.e.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":" nabla f(x)  leq epsilon","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"Consider dimension n=100 and we randomly assign x₀ to be a point in the 100-dimensional hypercube.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> x₀ = randn(100);","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"The entry point of scheme 71 occurs below on.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> optimize(rosen, ∇rosen!, x₀)\nSUCCESS 8.070336658758971e-7 ≤ 1.0e-5 in 528 steps\n--------------------------------------\n  Minimum f:      5.311172726630893e-16\n  Minimum ||∇f||: 8.070336658758971e-7\n  Minimum Δ:      0.005844719845773086\n  Minimum Step:   6.030122388810338e-8\n\n  Model: \n  -------------------\n    objective:         rosen\n    gradient:          ∇rosen!\n    initial iterate:   [0.132719, ..., 0.554169, -0.861590, -0.025498]\n    dimension:         100\n    directory:         /Users/daniel/.julia/dev/BlockOpt/docs/Missing\n    objective formula: missing\n  Driver:\n  -------------------\n    S_update:  S_update_c\n    QN_update: SR1\n    pflag:     false\n    Options:\n      samples:        6\n      Δ_max:          100.0\n      δ_tol:          1.0e-12\n      ϵ_tol:          1.0e-5\n      max_iterations: 2000\n  Trace:\n  -------------------\n    Weaver:\n      f_vals:   [37156.548946, ..., 0.000000, 0.000000, 0.000000]\n      ∇f_norms: [15116.003941, ..., 0.000293, 0.000016, 0.000001]\n      Δ_vals:   [5.984993, ..., 0.187031, 0.187031, 0.187031]\n      p_norms:  [5.172082, ..., 0.000045, 0.000002, 0.000000]\n      ρ_vals:   [0.931152, ..., 0.985198, 0.983784, 0.986492]\n    Profile:\n      trs_counter: 528\n      trs_timer:   0.07330679893493652\n      ghs_counter: 430\n      ghs_timer:   0.07087516784667969","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"Here, the output is showing a Simulation instance in it's terminal state, which happens to be a success!","category":"page"},{"location":"tutorials/simple/#Constructing-a-Model","page":"Simple Use Case","title":"Constructing a Model","text":"","category":"section"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"We extend our simple use case to define a model, which creates a directory to keep track of various simulations throughout the model's life.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> m = Model(\"Rosenbrock\")\n  Model: \n  -------------------\n    objective:         missing\n    gradient:          missing\n    initial iterate:   missing\n    dimension:         missing\n    directory:         /Users/daniel/.julia/dev/BlockOpt/docs/Rosenbrock\n    objective formula: missing","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"Above is an empty model which is incrementally loaded.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> objective!(m, rosen)\nrosen (generic function with 1 method)\n\njulia> gradient!(m, ∇rosen!)\n∇rosen! (generic function with 1 method)\n\njulia> m\n  Model: Rosenbrock\n  -------------------\n    objective:         rosen\n    gradient:          ∇rosen!\n    initial iterate:   [-1.177973, ..., -0.535732, 1.304151, 1.194971]\n    dimension:         100\n    directory:         /Users/daniel/.julia/dev/BlockOpt/Rosenbrock\n    objective formula: missing","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"The model is now loaded to a final state meaning that the objective and gradient function can no longer be modified. ","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"We may optionally set a formula for the objective function of model m. The formula is used in the trace plots which may be generated from the simulation.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> rosen_formula = \"\\$\\\\sum_{i=1}^{N-1} \\\\left[100(x_{i+1}^2 - x_i^2)^2 + (1 - x_i)^2\\\\right]\\$\";\n\njulia> formula!(m, rosen_formula)\n\"\\$\\\\sum_{i=1}^{N-1} \\\\left[100(x_{i+1}^2 - x_i^2)^2 + (1 - x_i)^2\\\\right]\\$\"\n\njulia> m\n  Model: Rosenbrock\n  -------------------\n    objective:         rosen\n    gradient:          ∇rosen!\n    initial iterate:   [-1.177973, ..., -0.535732, 1.304151, 1.194971]\n    dimension:         100\n    directory:         /Users/daniel/.julia/dev/BlockOpt/Rosenbrock\n    objective formula: $\\sum_{i=1}^{N-1} \\left[100(x_{i+1}^2 - x_i^2)^2 + (1 - x_i)^2\\right]$","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"Our model m is fully constructed. Observe the directory path above, it was created in your present working directory using the name given to the model constructor.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"See the Model section of Manual for more information.","category":"page"},{"location":"tutorials/simple/#Constructing-a-Driver","page":"Simple Use Case","title":"Constructing a Driver","text":"","category":"section"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"The goal of creating a model is to record simulation information over multiples trials, where each trial incorporates the second-order hessian information into a step's QN update in a unique manner. Each trial is driven by a unique set of parameters, which are represented in a Driver instance. ","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"A default drive is constructed below with the passing of an empty argument list.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> default_driver = Driver() # default parameters and options\n  Driver:\n  -------------------\n    S_update:  S_update_c\n    QN_update: SR1\n    pflag:     false\n    Options:\n      samples:        6\n      Δ_max:          100.0\n      δ_tol:          1.0e-12\n      ϵ_tol:          1.0e-5\n      max_iterations: 2000","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"The default_driver is created in all optimize that don't specify a Driver. Below we pass PSB as argument for the QN_update keyword.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> psb_driver = Driver(QN_update = PSB)\n  Driver:\n  -------------------\n    S_update:  S_update_c\n    QN_update: PSB\n    pflag:     false\n    Options:\n      samples:        6\n      Δ_max:          100.0\n      δ_tol:          1.0e-12\n      ϵ_tol:          1.0e-5\n      max_iterations: 2000","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"See pflag and S_update for information on the other keyword arguments.","category":"page"},{"location":"tutorials/simple/#Configurations","page":"Simple Use Case","title":"Configurations","text":"","category":"section"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"By passing a model to optimize with a number of unique drivers, we can gain insight into the effects of driver configurations. We saw above how m performed with the default driver configuration, now we run it with the PSB update.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> optimize(m, psb_driver)\nFAIL 3.566862431214296 ≰ 1.0e-5 in 2000 steps\n--------------------------------------\n  Minimum f:      28.577172626527943\n  Minimum ||∇f||: 1.1239260593910936\n  Minimum Δ:      0.0055605929272336966\n  Minimum Step:   0.005560592927233694\n\n  Model: Rosenbrock\n  -------------------\n    objective:         rosen\n    gradient:          ∇rosen!\n    initial iterate:   [-1.177973, ..., -0.535732, 1.304151, 1.194971]\n    dimension:         100\n    directory:         /Users/daniel/.julia/dev/BlockOpt/Rosenbrock\n    objective formula: $\\sum_{i=1}^{N-1} \\left[100(x_{i+1}^2 - x_i^2)^2 + (1 - x_i)^2\\right]$\n  Driver:\n  -------------------\n    S_update:  S_update_c\n    QN_update: PSB\n    pflag:     false\n    Options:\n      samples:        6\n      Δ_max:          100.0\n      δ_tol:          1.0e-12\n      ϵ_tol:          1.0e-5\n      max_iterations: 2000\n  Trace:\n  -------------------\n    Weaver:\n      f_vals:   [35819.088644, ..., 28.644942, 28.610707, 28.577173]\n      ∇f_norms: [14013.886569, ..., 3.567714, 3.387636, 3.566862]\n      Δ_vals:   [5.694047, ..., 0.044485, 0.044485, 0.044485]\n      p_norms:  [4.372943, ..., 0.014306, 0.014309, 0.014314]\n      ρ_vals:   [1.128439, ..., 1.664845, 1.670837, 1.665141]\n    Profile:\n      trs_counter: 2000\n      trs_timer:   3.959573268890381\n      ghs_counter: 1974\n      ghs_timer:   0.4726881980895996","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"Here, the simulation failed to reach a successfull terminal state and instead reached the maximum number of allowed iterations. It is expected that the PSB update requires more iterations than the default SR1 update. Letting this guide us, we increase the max_iterations of the psb_driver to larger value.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> max_iterations!(psb_driver, 10000)\n10000\n\njulia> optimize(m, psb_driver)\nSUCCESS 9.93303363395617e-6 ≤ 1.0e-5 in 5578 steps\n--------------------------------------\n  Minimum f:      3.986623854354119\n  Minimum ||∇f||: 9.93303363395617e-6\n  Minimum Δ:      0.004905284751681128\n  Minimum Step:   6.309128627600796e-8\n\n  Model: Rosenbrock\n  -------------------\n    objective:         rosen\n    gradient:          ∇rosen!\n    initial iterate:   [-1.177973, ..., -0.535732, 1.304151, 1.194971]\n    dimension:         100\n    directory:         /Users/daniel/.julia/dev/BlockOpt/Rosenbrock\n    objective formula: $\\sum_{i=1}^{N-1} \\left[100(x_{i+1}^2 - x_i^2)^2 + (1 - x_i)^2\\right]$\n  Driver:\n  -------------------\n    S_update:  S_update_c\n    QN_update: PSB\n    pflag:     false\n    Options:\n      samples:        6\n      Δ_max:          100.0\n      δ_tol:          1.0e-12\n      ϵ_tol:          1.0e-5\n      max_iterations: 10000\n  Trace:\n  -------------------\n    Weaver:\n      f_vals:   [35819.088644, ..., 3.986624, 3.986624, 3.986624]\n      ∇f_norms: [14013.886569, ..., 0.000010, 0.000011, 0.000010]\n      Δ_vals:   [5.023012, ..., 0.039242, 0.039242, 0.039242]\n      p_norms:  [4.096592, ..., 0.000000, 0.000000, 0.000000]\n      ρ_vals:   [1.160497, ..., 1.756820, 1.760699, 1.763252]\n    Profile:\n      trs_counter: 5578\n      trs_timer:   0.891240119934082\n      ghs_counter: 5552\n      ghs_timer:   0.9388515949249268","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"Allowing for 10000 iterations is more then enough to reach convergence within the the tolerance given by ϵ_tol(psb_driver) (10e-5). ","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"See the Options and Driver sections of the Manual for more information on Driver options and configurations. ","category":"page"},{"location":"tutorials/simple/#Simulation-Recipes","page":"Simple Use Case","title":"Simulation Recipes","text":"","category":"section"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"Let us assign the variables s1 and s2 as returned terminal simulations driven by drivers d1 and d2 as defined below.","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> d1 = Driver(S_update=S_update_a)\njulia> d2 = Driver(S_update=S_update_d)\njulia> s1 = optimize(m, d1);\njulia> s2 = optimize(m, d2);","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"We have configured drivers d1 and d2 to use updates (6.1.a) and (6.1.d).","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"Next we create the objective function trace plot with the Julia Plots package. The plotted data may be accessed using f_vals(s1) and f_vals(s2).","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> using Plots;     # to install: using Pkg; Pkg.add(\"Plots\")\njulia> objtrace(s1, s2)","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"(Image: )","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"The normed gradient data at each successful iterate is accessed through ∇f_norms(s1) and ∇f_norms(s2).","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"julia> gradtrace(s1, s2)\n","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"(Image: )","category":"page"},{"location":"tutorials/simple/","page":"Simple Use Case","title":"Simple Use Case","text":"See: radiustrace, steptrace, rhotrace which have corresponding ! versions.","category":"page"},{"location":"#BlockOpt.jl","page":"Introduction","title":"BlockOpt.jl","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"This application supplements QN Optimization with Hessian Samples, an article currently under review. It's purpose is to explore block Quasi-Newton (QN) updates used in the unconstrained minimization of a smooth objective function, f. ","category":"page"},{"location":"#Documentation-Structure","page":"Introduction","title":"Documentation Structure","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The Overview section is concerned with the sofware design pattern used.\nThe Manual section holds documentation for the BlockOpt application programable interface.\nThe Tutorial sections provides typical use cases of BlockOpt.jl.","category":"page"},{"location":"tutorials/installation/#Installation","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"tutorials/installation/","page":"Installation","title":"Installation","text":"The BlockOpt package installs as","category":"page"},{"location":"tutorials/installation/","page":"Installation","title":"Installation","text":"julia> ]\npkg> add https://github.com/danphenderson/TRS.jl\npkg> add https://github.com/danphenderson/BlockOpt.jl # backspace returns to julia prompt ","category":"page"},{"location":"tutorials/installation/","page":"Installation","title":"Installation","text":"in the Julia's Pkg REPL mode.","category":"page"},{"location":"tutorials/installation/","page":"Installation","title":"Installation","text":"In a notebook environment BlockOpt installs as","category":"page"},{"location":"tutorials/installation/","page":"Installation","title":"Installation","text":"using Pkg\nPkg.add(url=\"https://github.com/danphenderson/TRS.jl\")\nPkg.add(url=\"https://github.com/danphenderson/BlockOpt.jl\")","category":"page"},{"location":"tutorials/installation/","page":"Installation","title":"Installation","text":"using the Julia package manager Pkg.jl.","category":"page"},{"location":"tutorials/installation/","page":"Installation","title":"Installation","text":"The TRS package is an unregistered package  requirement for BlockOpt.jl. There is an open pull-request to merge the  forked branch of TRS.jl used in this packages trust-region subproblem solve. The pull request focuses on updating the master branch to the latest  evolution of the Julia package management system.","category":"page"}]
}
